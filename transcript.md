# Deploying an open-source project to Digital Ocean using Terraform and Terraform Cloud - Transcript

Hello everyone!  It is really good to be here with you today, albeit in recorded format, at HashiTalks Australia and New Zealand.  And I am here to talk to you about an open-source project of mine, and how my team and I deployed it to Digital Ocean using Terraform and Terraform Cloud. Obviously, with that, I'm talking about a bunch of different tools.  So if you want to know about all of the tools that I used, you can scan the QR code on the slide that's up at the moment, or go to the Github link.  That has a list of all of the tooling, as well as some sources of- tips and tricks that I used in working out how to put things together.

To begin with, I would like to acknowledge the Wurundjeri people of the Kulin Nation, on whose land this recording is being made.  This is, and always will be, Aboriginal land.  Their sovereignty is never ceded.

Probably most of the audience doesn't know me!  My name is Dawn; I do cloud security and DevOps type work at Innablr; we are a little consultancy in Melbourne, Australia; and we are hiring, we are happy to help you solve your Terraform problems - I'm sure that everyone here has a similar pitch, but if you want to know about that, you can come and find us.  And sometimes I get to go down open-source rabbit holes outside the world of work.  I am also, outside the world of work, an occasional author and kitchen alchemist - sometimes that ends really well, sometimes that ends badly - and I am a raging sportsball fan, which is why that picture of me is me in a Boston Bruins sweater, and why I'm wearing a New England Patriots jersey today.

So, I couldn't explain to you how we actually did the technical side without giving you a little bit of background.  This particular open-source project of mine started in late 2017 - erm, I was part, at the time of the Melbourne writing community, erm, I was fairly significantly involved in a couple of different groups, and one thing that a lot of people talked about - and there were some chatbot-like applications that did this - but wanting to do things like goal-tracking, wanting to do things like set timers and see how many words they could write in those times, to do collaborative writing and challenge writing, and being able to do that in a lightweight way, using the applications that they were already using.  What I ended up doing was I built a fairly basic little chatbot called Winnie.  And Winnie had a lot of these things built in: goal-tracking, prompts, she would do timers so that you could do collaborative writing or contest writing.

And that was really good.  But one of the things with that is this was not just a hobby project.  This was something that there were actually other people using.  And so I'm looking at this and going 'alright, I have to work out a way to do this that is relatively stable, relatively reliable', because at the time I had a Raspberry Pi and a terrible Internet connection.  Thank you, Australia!  To make matters worse, the bug brigade that I was dealing with was partly caused by the fact that the early deployments to that essentially Raspberry Pi-like setup were all being done manually.  So there was no consistent deployment pattern, which meant that I was ending up with a bunch of bugs.

In terms of solving the problem of whether things were up or not, that was relatively easy, because I could do it with cloud hosting.  There are a lot of providers which will give you a VM for not a hell of a- for not a hell of a lot of money, for varying levels of stability.  And, at the time, as well as cloud hosting, I was also becoming interested in DevOps.  And I went 'you know what, I can solve the deployment problem as well, and I can do that with CI/CD'.  So what I ended up with, in terms of trying to solve the initial bug brigade, was a virtual machine on a cloud host, and CI/CD which was based on CLI scripts.  So the commands that were being run, and the methods that they were being run with, were consistent from deployment to deployment.

This worked fine - until the user base started to grow.  The original user base for Winnie was largely based in Australia.  What I hadn't anticipated when I was setting up this original CLI was that I was going to end up with about 1000 users across 4 continents - it might be 5, I don't know.  More than one, at any rate!  And so then you run into issues of, yeah, chat bots are fairly lightweight, but in terms of the scalability and reliability, what's the best way to do that?  The other issue I was running up against was I was essentially the only person that had built this - I'd done all of the software and I hadn't done it well.  So I went OK, I need to find myself a team, with the aim of freeing myself up to solve the problems that I'm good at.  The infrastructure plo- problems, the- the deployment problems.

And what I ended up with, ah was we had a team, erm, we had and still have a team of three people.  We had me, there in the centre.  On the left we have the ostensibly competent dev, who's actually quite a competent dev, and her role was basically to tame the code base.  To take this bodge job code that I had produced, and get it to something that was workable, that was repeatable, that had a minimum number of bugs.  On the right was the project manager, and his job was to set deadlines, make sure that we were staying on track, evaluate task-tracking tools, and make sure that we had, you know, things like a code of conduct, things that are important for the community side.  And this freed me, in the middle, up to do what I am really good at.  And that is the infrastructure side of things.

So when we were looking at this major overhaul, there were two b- aspects of this which were my responsibility.  The first one was: we were using MongoDB for all of the data.  And that is absolutely fine, until you discover that you need relational data.  So we needed to migrate the database from MongoDB to some sort of relational database.  The engine that we ended up settling on was Postgres. The other thing that I needed to work out was how to find a stable and functional cloud host, and to make sure that we were going to be able to do deployments consistently.

In the open-source world, there is a conversation about budgets, and that conversation about budgets is often completely different to what you get in a commercial environment.  I did not have many $50 billion notes.  This was essentially being run on a shoestring budget of whatever change I could shake loose from the back of my bank account.  And what this meant was that I had to come up with a set of tools which were not going to completely break the bank.  One of the beautiful things about HashiCorp's tools is that Terraform and Vault, which are the two tools that sort of run at the base of everything, are open-source.  And when you're looking at add-ons, things like Terraform Cloud, quite a few of those are free for small teams.

So in terms of where the money was actually going to go, that was going to be to the cloud hosting.  And our decision with that was we were going to go with Digital Ocean.  For a couple of different reasons; the first one is that Digital Ocean has a level of reliability which is not that far behind the three big cloud providers.  I've been told also that Digital Ocean does a really good managed Kubernetes offering, although that wasn't something we were using.  But without needing to mess around with things like capacity reservations, Digital Ocean is really, really cheap.  Compared to things like AWS or Azure, it's a fraction of the price.  And another thing which was a draw for Digital Ocean in particular was that, unlike a lot of the much smaller cloud hosts where all that you can get are virtual machines, it does actually offer managed SQL databases which support Postgres.  Again, these have a lot of the features of the- the same types of things that the big three will give you.

In terms of CI/CD, considering that we were in Github, that was a no-brainer.  Github Actions is free for open-source software, and it offers hosted build machines, which meant that we didn't have to worry about setting up build machines on the cloud somewhere, we could just go to Github Actions 'hey, you have the machines, please go away, do the thing'. But the core of the bits of this that I was responsible for, specifically the infrastructure, are two HashiCorp tools, Terraform and Terraform Cloud.  Digital Ocean does not have its own way of doing infrastructure as code, but- another very, very good thing about Terraform is that because there is no vendor lock-in, pretty much anyone can go away and build a Terraform provider for anything that offers an API, which Digital Ocean does.  So Digital Ocean has a very well-supported Terraform provider.  Terraform is entirely free to use; didn't have to worry about licensing, wasn't locked into a particular ecosystem like you would be if you used a cloud provider's tools.  Terraform is also entirely open-source, and considering that this is an open-source project, that fits with the ethos.

The other problem that we then needed to solve was the problem of how to manage state.  Because if you're in something like AWS or Azure, the very common way that people will manage state is by just sticking it in, you know, an S3 bucket, or sticking it on Azure Blob Storage, or whatever the GCP equivalent is, I don't know off the top of my head.  Digital Ocean does offer S3-compatible storage in the form of Digital Ocean Spaces, but in order to use that, we would have had to pay five dollars per month to store one file.  And I didn't want to have to deal with a multi-cloud setup just for that.  But Terraform Cloud is a managed HashiCorp offering which does all of that for you, and it is free for up to five users, which was basically perfect for our team of three.

So.  That's the tooling, now let's see how all of this fits together.  So in terms of what we have in the actual repository, if we go in and look at how the Terraform files are actually set-up, this is all fairly lightweight.  What you've got is we've got one Digital Ocean droplet, we've got one database - they interface with each other - we have a set of variables, and we have the provider.  The Terraform provider for this is pretty much just the Digital Ocean provider, which is interfacing directly with the Terraform Cloud as a remote backend.  That Digital Ocean token is being pulled in via Github.  One of the really nice things about Github Actions is it does a lot of the secret storage very well, so I didn't have to go away and set-up something like a HashiCorp Vault.

And then if we go and look at the database itself, this is really the bulk of what the application actually needs.  That managed database piece is what it's very hard to get unless you go with, you know, your big, your AWS and CloudFormation or your Azure and ARM templates.  Being able to do this affordably for a small project would not really be possible without Digital Ocean and Terraform.  So I'm running essentially the smallest cluster that Digital Ocean will give us.  Everything is running in Amsterdam, because it was easiest in terms of GDPR.  But we essentially have Terraform, which is setting up a database cluster with Postgres 13 as the engine.  We are then creating a database.  In the cluster ID it has a particular name, that's all relatively straightforward.  But one thing that is quite nice about being able to do things like this using Terraform is I can also have it manage firewall rules.  Again, this is super lightweight, but we are actually holding people's personal data here, even though it's an open-source project, you want to be careful of that, and Terraform - leveraging Terraform to actually do the deployments for those sorts of things means that you can make sure that you're not doing this manually.

So what we have is we have a database firewall which depends on the droplet, a- because this will deploy 2 rules.  The first rule that it deploys is one which allows the cluster to talk to the droplet, which is handling all of the traffic coming into the chatbot and passing it off to the database.  The second rule that we have open is we have a separate server which we can use for manually querying the database, which we use for some very very basic data analytics.  We've disclosed all of that to everyone in the privacy policy.  But mostly, the value- the value of being able to setup those firewall rules and to have things like the Redash server is that we can go in and we can do some manual queries, verify that the way that we've got everything set up is how it should be, while also making sure that we are able to legitimately say to people 'nobody else can access this data and we're pretty sure of that', that's something that Terraform allows you to do.  You get back a database connection URI, that then gets plugged into the, erm, - it gets plugged into the- droplet.

The actual droplet itself is probably even simpler, if truth be told.  You need to have an SSH key.  At the moment nobody can get into that box, but in order to create a Digital Ocean droplet, and for particular aspects of the analytics, they recommend that you have an SSH key.  We store that in Github Actions secrets.  The droplet itself, again, is pretty much the smallest droplet that Digital Ocean offers, it's running Debian because that is simple, it's in Amsterdam.  And we have the same sort of deal where we have firewall rules which are blocking any malicious traffic.  Being able to codify this in Terraform is super important for the type of stuff that we're doing.  We are not allowing - e- essentially what we're allowing is we're allowing, erm, TCP, SSH just for Github Actions, so that Github Actions can do the deployments to the droplet, HTTPS, outbound TCP, outbound UDP - because this is a chatbot that runs on Discord, those are all of the permissions that you need for Discord, but you can only get in through that frontend.  And again, you get back an IP address, which is used for configuration.

And in terms of the variables that we're looking at, this is where Terraform sort of starts to interface with Github Actions; so the Redash IP address is not public, that's our querying server; the Digital Ocean token, obviously you don't want to make that public, because then anyone can access it; and we want to have an IP address for the runner because in those firewall rules we can actually lock down SSH access then so that it's only the Github Actions runner that does the deployment which can actually mess around with this.

So- in terms of how the actual- workflow works, all that you then need to do here when you want to release this is - set up Terraform, there's a Github action for that, it's super simple; go away and get the IP address of the Github Actions runner, we're doing that for security reasons; then you build your Terraform variables file, and we're taking some of the secrets that we've stored and just interpolating those directly into the Terraform variables file; and just run a Terraform init, Terraform plan, Terraform apply command.  This is the same sort of stuff that you would do at big companies that use these Terraform workflows, but because Terraform is free and open-source and we can use it for Digital Ocean, we can do this for zero cost.  And what you get back from that is your private database connection string and a droplet IP address.  The rest of the deployment workflow is then deploying the application onto Terraform- or onto Digital Ocean using that configuration.

The other very important part here is obviously you need to store the state, and the tool that we are doing that with is Terraform Cloud.  This is free for up to 5 users, and the integration is absolutely amazing.  You can actually get Terraform Cloud to integrate in directly with, erm, the Github Actions CLI, so that it will tell you what has changed anytime you run.  I'm not going to show you the output screen because I'm fairly sure that that's got secrets in it, but you can see again: from Terraform Cloud you get a list of resources. If you are in a much bigger environment, this is all searchable, but the main thing that we're using Terraform Cloud here is to have that central location to manage the state.

And when we get into Digital Ocean, obviously I've censored the IP address of the actual bot here, but you get pretty much what you would expect.  You get a droplet, you get a database cluster.  The beauty of this is that the only bill that I pay every month is the bill for Digital Ocean.  The database cluster in and of itself - if we go in and have a little look at that - again, this is super straightforward.  There's some information about what's restricted - again, we've got an IP address here which is blocked out, that's the IP address of the server - but the sources that we are allowing are very, very limited.  Likewise, if we go and have a look at the, erm, the droplet - this will take a minute to load - you can see if we go and look at things like the firewalls, which it's going to take me a minute to find because I've forgotten where they are...  There we go.  There's some firewalls, you can see that IP address there which is partially blocked out, that's literally just a Github Actions runner IP address.  So, for zero effort, with an entirely repeatable process, this is all locked down.  And this costs me the princely sum of 33 Australian dollars a month to do this whole thing.  The only bill that I pay is the bill for Digital Ocean.  Terraform, Terraform Cloud, Github Actions, that is all entirely free.

So in terms of using Terraform here, there are a number of advantages.  Terraform is one of the very very few tools which allows you to do this sort of thing at a small scale without locking yourself into a particular cloud provider.  When you're dealing with super lightweight infrastructure, obviously you can't just take resources from one Terraform provider and plug them directly into another Terraform provider, but when you're dealing with super lightweight infrastructure, it would be very easy for us to take this paradigm, and to decide that we wanted to deploy it to an AWS, an Azure, a GCP - anything that's supported by Terraform, if they came to us and said 'hey, we can do this to you for much cheaper than Digital Ocean can'.  Having that flexibility is really important.

Another thing that's very important there is having the repeatability, and that's where- the fact that Digital Ocean has this really powerful API, and the fact that there is a very well-supported Terraform provider makes a lot of what we're doing here possible, because with a lot of the other cloud hosts, you would have to do this sort of thing the old school sysadmin way, but we can have all of the deployments, everything, just managed by Terraform.  We don't even have to worry about going in somewhere and creating a database on an existing cluster, Terraform's doing the database for us too.  So when you deploy the code and set everything up, there's zero overhead beyond having Terraform set up the infrastructure, and beyond the deployment of the code.

And part of the reason why this works so well is because it is very modular.  We can plug and play, you know, we can- we can pull bits out and plug in other bits as we need to.  Terraform, Terraform Cloud, the HashiCorp tools as the backbone of that, they're what makes that possible.  Because Terraform is so widely used, because it is supported by a lot of clouds, and because there are a lot of community-produced APIs, the other thing that it gives us confidence in is, you know, if we need to swap out the cloud, we can do that very easily, but we also have a degree of modularity there, so if we found ourselves needing to bolt on other services, or if we found ourselves needing to do more with this, Terraform gives you that ability, where a tool that's native to a vendor doesn't necessarily give you that.

And one other thing that I think is probably also important to call out here, although it's something that may not necessarily seem immediately obvious, is that from any machine, wherever, as long as the three of us have our password managers, we can manage all of this from wherever we want.  We're not reliant on a Raspberry Pi in someone's house running on an unstable internet connection, and there are [emphatically] so, so many open-source projects that are reliant on that sort of situation.  We've got - I mean, Digital Ocean is very near world-class in terms of the reliability of it as cloud infrastructure.  Terraform is an enterprise-grade tool.  This is something that probably most of you here today, if you're using Terraform or Terraform Cloud, you're using them in your enterprise environments.  We can access all of this from the cloud.  Github and Github Actions are very very commonly used in the enterprise environment as well.  And that is really cool, because we're essentially using the same sort of tools that we would be using at work, but we're using them on a smaller scale, to stay within budget, with secure, reliable, repeatable deployments, where we can make sure that the firewall rules are doing what we think they are, and we don't have to rely on manual processes.  And there are a bunch of scenarios, and a bunch of situations, where you will see people talk about using these tools in an- at an enterprise level.  But I think it is also really important to highlight the value of open-source tools in terms of building out the open-source ecosystem.  We couldn't do this for 1000 users with anything approaching a remotely reasonable degree of reliability if not for the fact that we can leverage the sort of tools that we use in our day-to-day work.

That is all.  I believe we're going to have a little bit of time for questions.  Erm, otherwise, contacts are up there, there is also a link to the- my talks repository, which has a copy of all of the previous talks that I have done.  I know that this was probably a bit of an interesting talk that was a little bit off the beaten path for these scenarios where we usually deal with enterprise-type things, but I'm hoping that if you've had that idea for some sort of open-source project, and you're going 'I want to run this without absolutely blowing out the cost', now you've got some idea of one particular toolchain that you can use to make that happen, which is also the type of toolchain that you'd be using in your day-to-day work.
